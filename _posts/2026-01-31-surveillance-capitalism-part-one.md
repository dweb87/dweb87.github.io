---
layout: post
title: Surveillance Capitalism - Part 1
subtitle: Why the Story We Tell Ourselves About Digital Advertising Doesn’t Quite Fit
date:   2026-01-31 08:30:00 +0000
tag: Marketing
---

### Surveillance Capitalism: Why the Story We Tell Ourselves About Digital Advertising Doesn’t Quite Fit

If you work in digital marketing, you’ve almost certainly absorbed some version of the idea that platforms like Google and Meta operate through *surveIllance*: they track users, predict behaviour, and use that knowledge to influence or control outcomes. This story has become so dominant that it now frames how marketers, regulators, journalists, and even platforms themselves talk about digital advertising. It’s a compelling narrative — but it doesn’t quite match how these systems behave in practice.

The most influential version of this argument describes digital advertising as a form of “surveillance capitalism,” where companies extract behavioural data, turn it into predictions, and monetise those predictions through ever more precise targeting. From this perspective, the core power of platforms lies in certainty: knowing users better than they know themselves, and using that knowledge to shape future behaviour. Marketers are positioned as beneficiaries of this precision, buying access to predictive insight at scale.

The problem is that anyone who has actually run campaigns knows this picture is unstable. Targeting is inconsistent, results are volatile, attribution never quite lines up, and optimisation often feels like steering in fog rather than executing a precise plan. Audiences don’t behave as predicted, performance shifts without obvious causes, and platforms routinely contradict their own explanations. If surveillance and prediction were as total as the theory suggests, digital advertising would feel far more controlled than it does.

To account for this gap, marketers often fall back on familiar explanations: the data isn’t clean enough, the algorithm needs more time, the budget is too small, privacy changes have broken the system, or the platform is a “black box.” These explanations preserve the idea that the system *should* work predictively, even if it currently doesn’t. The underlying assumption that platforms deliver certainty and control remains intact.

But this assumption has consequences. It encourages marketers to overestimate what platforms know, overtrust what metrics claim to show, and internalise uncertainty as failure. It also fuels ethical debates that swing between panic (“we’re manipulating people”) and denial (“users consented, it’s fine”), both of which rely on the same belief that platforms are coherent systems of behavioural control.

What if the problem isn’t that surveillance capitalism has gone wrong but that we’ve misunderstood what kind of system digital advertising actually is? In the next post, I’ll argue that platforms are not engines of certainty at all, but fragile, opportunistic markets that *depend* on uncertainty to function, and that seeing them this way changes how we understand power, performance, and our own role as marketers within them.
